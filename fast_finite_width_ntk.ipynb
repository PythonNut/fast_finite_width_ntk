{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_finite_width_ntk.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Sl2JyRE1hK-z",
        "dNMGKyttrRkC",
        "0lWFC3QEgao4",
        "t1DLRESpXg7L",
        "Dh_aFUZFXm_C"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otnqBdyaYBrf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iclr2022anon/fast_finite_width_ntk/blob/main/fast_finite_width_ntk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTt0UNQbk_Td"
      },
      "source": [
        "# Example of computing NTK of a ResNet18 on ImageNet inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvXMUSdFjCqq"
      },
      "source": [
        "Tested on NVIDIA A100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl2JyRE1hK-z"
      },
      "source": [
        "# Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HunkuGjSr63O",
        "outputId": "13b8ac1d-e19e-414a-8775-2a7397dd6bb4"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: A100-SXM4-40GB (UUID: GPU-86b15d1f-66b5-ce97-b20b-478dcdd8b578)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HggahVnItsvW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpkoKz4bXSsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13a0460-3d6b-4b49-9948-dd5e442e2a57"
      },
      "source": [
        "!pip install git+https://github.com/iclr2022anon/fast_finite_width_ntk.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/iclr2022anon/fast_finite_width_ntk.git\n",
            "  Cloning https://github.com/iclr2022anon/fast_finite_width_ntk.git to /tmp/pip-req-build-0imnjqcs\n",
            "  Running command git clone -q https://github.com/iclr2022anon/fast_finite_width_ntk.git /tmp/pip-req-build-0imnjqcs\n",
            "Requirement already satisfied: jax>=0.2.21 in /usr/local/lib/python3.7/dist-packages (from fast-finite-width-ntk==0.0.1) (0.2.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->fast-finite-width-ntk==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->fast-finite-width-ntk==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->fast-finite-width-ntk==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.7/dist-packages (from jax>=0.2.21->fast-finite-width-ntk==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->jax>=0.2.21->fast-finite-width-ntk==0.0.1) (1.15.0)\n",
            "Building wheels for collected packages: fast-finite-width-ntk\n",
            "  Building wheel for fast-finite-width-ntk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fast-finite-width-ntk: filename=fast_finite_width_ntk-0.0.1-py3-none-any.whl size=28366 sha256=83e6fb6e81bd71fc2687e61a1aec6a4638670f9c84693f048498978a3e772205\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-075q0f2n/wheels/db/fb/b7/058742012f3055a77cab8aea1f0b07dfaa734f4addf5405cbf\n",
            "Successfully built fast-finite-width-ntk\n",
            "Installing collected packages: fast-finite-width-ntk\n",
            "Successfully installed fast-finite-width-ntk-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNMGKyttrRkC"
      },
      "source": [
        "# FLAX Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W87de54OpuO8",
        "outputId": "7207dff9-da1b-4eba-b116-cbcfe69ca1ed"
      },
      "source": [
        "# Install ml-collections & latest Flax version from Github.\n",
        "!pip install -q clu ml-collections git+https://github.com/google/flax\n",
        "\n",
        "example_directory = 'examples/imagenet'\n",
        "editor_relpaths = ('configs/default.py', 'input_pipeline.py', 'models.py', 'train.py')\n",
        "\n",
        "repo, branch = 'https://github.com/google/flax', 'main'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |████▏                           | 10 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 20 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 30 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 40 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.6 MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 45.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 51 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 61 kB 22.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 71 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 81 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 19.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.7 MB/s \n",
            "\u001b[?25h  Building wheel for flax (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cMTM3W4hcsZ"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVAH-aWN3NzF"
      },
      "source": [
        "# Install ml-collections & latest Flax version from Github.\n",
        "!pip install -q clu ml-collections git+https://github.com/google/flax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwX8bCNEGhJM"
      },
      "source": [
        "example_directory = 'examples/imagenet'\n",
        "editor_relpaths = ('configs/default.py', 'input_pipeline.py', 'models.py', 'train.py')\n",
        "\n",
        "repo, branch = 'https://github.com/google/flax', 'main'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "o65RonwHp4Y9",
        "cellView": "form",
        "outputId": "667dade4-1bfd-426c-d744-f0adb3991829"
      },
      "source": [
        "# (If you run this code in Jupyter[lab], then you're already in the\n",
        "#  example directory and nothing needs to be done.)\n",
        "\n",
        "#@markdown **Fetch newest Flax, copy example code**\n",
        "#@markdown\n",
        "#@markdown **If you select no** below, then the files will be stored on the\n",
        "#@markdown *ephemeral* Colab VM. **After some time of inactivity, this VM will\n",
        "#@markdown be restarted an any changes are lost**.\n",
        "#@markdown\n",
        "#@markdown **If you select yes** below, then you will be asked for your\n",
        "#@markdown credentials to mount your personal Google Drive. In this case, all\n",
        "#@markdown changes you make will be *persisted*, and even if you re-run the\n",
        "#@markdown Colab later on, the files will still be the same (you can of course\n",
        "#@markdown remove directories inside your Drive's `flax/` root if you want to\n",
        "#@markdown manually revert these files).\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "  import os\n",
        "  os.chdir('/content')\n",
        "  # Download Flax repo from Github.\n",
        "  if not os.path.isdir('flaxrepo'):\n",
        "    !git clone --depth=1 -b $branch $repo flaxrepo\n",
        "  # Copy example files & change directory.\n",
        "  mount_gdrive = 'no' #@param ['yes', 'no']\n",
        "  if mount_gdrive == 'yes':\n",
        "    DISCLAIMER = 'Note : Editing in your Google Drive, changes will persist.'\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    example_root_path = f'/content/gdrive/My Drive/flax/{example_directory}'\n",
        "  else:\n",
        "    DISCLAIMER = 'WARNING : Editing in VM - changes lost after reboot!!'\n",
        "    example_root_path = f'/content/{example_directory}'\n",
        "    from IPython import display\n",
        "    display.display(display.HTML(\n",
        "        f'<h1 style=\"color:red;\" class=\"blink\">{DISCLAIMER}</h1>'))\n",
        "  if not os.path.isdir(example_root_path):\n",
        "    os.makedirs(example_root_path)\n",
        "    !cp -r flaxrepo/$example_directory/* \"$example_root_path\"\n",
        "  os.chdir(example_root_path)\n",
        "  from google.colab import files\n",
        "  for relpath in editor_relpaths:\n",
        "    s = open(f'{example_root_path}/{relpath}').read()\n",
        "    open(f'{example_root_path}/{relpath}', 'w').write(\n",
        "        f'## {DISCLAIMER}\\n' + '#' * (len(DISCLAIMER) + 3) + '\\n\\n' + s)\n",
        "    files.view(f'{example_root_path}/{relpath}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'flaxrepo'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Counting objects: 100% (364/364), done.\u001b[K\n",
            "remote: Compressing objects: 100% (326/326), done.\u001b[K\n",
            "remote: Total 364 (delta 68), reused 180 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (364/364), 2.71 MiB | 12.80 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1 style=\"color:red;\" class=\"blink\">WARNING : Editing in VM - changes lost after reboot!!</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/examples/imagenet/configs/default.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/examples/imagenet/input_pipeline.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/examples/imagenet/models.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "      ((filepath) => {{\n",
              "        if (!google.colab.kernel.accessAllowed) {{\n",
              "          return;\n",
              "        }}\n",
              "        google.colab.files.view(filepath);\n",
              "      }})(\"/content/examples/imagenet/train.py\")"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcXZ-F3_zBuJ",
        "outputId": "2efa2355-fffd-417a-be0b-b8d047cfdaf6"
      },
      "source": [
        "# Note : In Colab, above cell changed the working direcoty.\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/examples/imagenet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt0rL4ycp4ZB"
      },
      "source": [
        "## Imports / Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EzOChfJeVrU",
        "outputId": "0c1aa2a0-23b3-4157-f85a-3031d6b7a298"
      },
      "source": [
        "# TPU setup : Boilerplate for connecting JAX to TPU.\n",
        "\n",
        "import os\n",
        "if 'google.colab' in str(get_ipython()) and 'COLAB_TPU_ADDR' in os.environ:\n",
        "  # Make sure the Colab Runtime is set to Accelerator: TPU.\n",
        "  import requests\n",
        "  if 'TPU_DRIVER_MODE' not in globals():\n",
        "    url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "    resp = requests.post(url)\n",
        "    TPU_DRIVER_MODE = 1\n",
        "\n",
        "  # The following is required to use TPU Driver as JAX's backend.\n",
        "  from jax.config import config\n",
        "  config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "  config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "  print('Registered TPU:', config.FLAGS.jax_backend_target)\n",
        "else:\n",
        "  print('No TPU detected. Can be changed under \"Runtime/Change runtime type\".')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No TPU detected. Can be changed under \"Runtime/Change runtime type\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdzHCJuop4ZB"
      },
      "source": [
        "import json\n",
        "from absl import logging\n",
        "import flax\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "logging.set_verbosity(logging.INFO)\n",
        "\n",
        "# assert len(jax.devices()) == 8, f'Expected 8 TPU cores : {jax.devices()}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O2C7AY3p4ZF"
      },
      "source": [
        "# Helper functions for images.\n",
        "\n",
        "def show_img(img, ax=None, title=None):\n",
        "  \"\"\"Shows a single image.\"\"\"\n",
        "  if ax is None:\n",
        "    ax = plt.gca()\n",
        "  img *= tf.constant(input_pipeline.STDDEV_RGB, shape=[1, 1, 3], dtype=img.dtype)\n",
        "  img += tf.constant(input_pipeline.MEAN_RGB, shape=[1, 1, 3], dtype=img.dtype)\n",
        "  img = np.clip(img.numpy().astype(int), 0, 255)\n",
        "  ax.imshow(img)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  if title:\n",
        "    ax.set_title(title)\n",
        "\n",
        "def show_img_grid(imgs, titles):\n",
        "  \"\"\"Shows a grid of images.\"\"\"\n",
        "  n = int(np.ceil(len(imgs)**.5))\n",
        "  _, axs = plt.subplots(n, n, figsize=(3 * n, 3 * n))\n",
        "  for i, (img, title) in enumerate(zip(imgs, titles)):\n",
        "    show_img(img, axs[i // n][i % n], title)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y1ru2Ovp4ZI"
      },
      "source": [
        "# Local imports from current directory - auto reload.\n",
        "# Any changes you make to train.py will appear automatically.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import input_pipeline\n",
        "import models\n",
        "import train\n",
        "from configs import default as config_lib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM24rCkDI3F8"
      },
      "source": [
        "from jax import jit\n",
        "from jax import numpy as np\n",
        "from jax import random\n",
        "\n",
        "from fast_finite_width_ntk import empirical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPh5LGz9JBK_"
      },
      "source": [
        "def get_ntk_fns(O: int):\n",
        "  # Define a ResNet18.\n",
        "  model = models.ResNet18(num_classes=O)\n",
        "\n",
        "\n",
        "  # f(x, \\theta)\n",
        "  def apply_fn(params, x):\n",
        "    return model.apply(params, x, train=False, mutable=['batch_stats'])[0]\n",
        "\n",
        "  kwargs = dict(\n",
        "      f=apply_fn,\n",
        "      trace_axes=(),\n",
        "      vmap_axes=0\n",
        "  )\n",
        "\n",
        "  # Different NTK implementations\n",
        "  jacobian_contraction = jit(empirical.empirical_ntk_fn(**kwargs, implementation=1))\n",
        "  ntvp = jit(empirical.empirical_ntk_fn(**kwargs, implementation=2))\n",
        "  str_derivatives = jit(empirical.empirical_ntk_fn(**kwargs, implementation=3))\n",
        "  auto = jit(empirical.empirical_ntk_fn(**kwargs, implementation=0))\n",
        "  \n",
        "  # Parameters \\theta\n",
        "  params = model.init(random.PRNGKey(0), x1)\n",
        "  return params, (jacobian_contraction, ntvp, str_derivatives, auto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lWFC3QEgao4"
      },
      "source": [
        "# $\\color{blue}O = 8$ logit, batch size $\\color{red}N = 8$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbExWKkUg9ew"
      },
      "source": [
        "Structured derivatives compute NTK fastest. NTK-vector products are actually slower in this setting, due to costly forward pass relative to parameters size, and therefore scales poorly with batch size $\\color{red}N$. While it scales better with $\\color{blue}O$ than other methods, it's not enough to overcome the $\\color{red}N^2$ forward passes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwhIZWqxKTlt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74bcc38-1cca-4cbb-eaec-dfbedd120402"
      },
      "source": [
        "O = 8\n",
        "N = 8\n",
        "\n",
        "# Input images x\n",
        "input_shape = (224, 224, 3)\n",
        "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
        "x1 = random.normal(k1, (N, *input_shape))\n",
        "x2 = random.normal(k2, (N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
            "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zObT8WnPggFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dcfe7f-fb1e-4048-8e3f-818ee933aaf2"
      },
      "source": [
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW9gJJ4qggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8221d12-a6b0-44c1-af7b-6ea79b268ad8"
      },
      "source": [
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFeWnqGQggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ebd76c-8086-424c-f29d-93592515b05a"
      },
      "source": [
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 8, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q63v1L1aggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9feea3-6aa0-4c90-ba28-88f77b166785"
      },
      "source": [
        "# Make sure kernels agree.\n",
        "print(\n",
        "    np.max(np.abs(k_1 - k_2)) / np.mean(np.abs(k_1)), \n",
        "    np.max(np.abs(k_1 - k_3)) / np.mean(np.abs(k_1)),\n",
        "    np.max(np.abs(k_2 - k_3)) / np.mean(np.abs(k_2))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005016228 0.00067423016 0.0006507741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7AEZ9fggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e32ff26-73c5-4e65-b5ad-92394e009d41"
      },
      "source": [
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impl=1, flops=3964546560.0\n",
            "impl=2, flops=20214009856.0\n",
            "impl=3, flops=4283323904.0\n",
            "(8, 8, 8, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diP7nkBuggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89e991f6-c637-4960-9d67-b90617b5cd8c"
      },
      "source": [
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 139 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wehCdvi2ggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390f23d2-3c46-4d59-93a4-8928e6e2c819"
      },
      "source": [
        "%%timeit\n",
        "# Slower - forward pass (FP) is expensive relative to parameters.\n",
        "# Time cost scales poorly with batch size N.\n",
        "ntk_fn_ntvp(x1, x2, params).block_until_ready()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 140 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrm53akVggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784f8f9c-0483-4f56-f01b-efedb0e93c4d"
      },
      "source": [
        "%%timeit\n",
        "# 3X faster.\n",
        "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 46.5 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1QtkBqLggFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ceb751-14a4-4ccb-dec4-73aeb64dc213"
      },
      "source": [
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 139 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DLRESpXg7L"
      },
      "source": [
        "# $\\color{blue}O = 128$ logits, batch size $\\color{red}N = 1$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfoHOoT-gGy6"
      },
      "source": [
        "Both NTK-vector products and Structured derivatives compute NTK faster than Jacobian contraction. NTK-vector products incur no penalty when batch size $\\color{red}N = 1$, and leverage their beneficial scaling with large $\\color{blue}O = 128$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oHBaAmDhBON"
      },
      "source": [
        "O = 128\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "input_shape = (224, 224, 3)\n",
        "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
        "x1 = random.normal(k1, (N, *input_shape))\n",
        "x2 = random.normal(k2, (N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc1bUvL-KrK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0259a861-a64a-4629-e500-5965d4bdb6eb"
      },
      "source": [
        "# Jacobian contraction\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdNsmnjOKyp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ba544d-b436-43e5-dec2-7b6cc5424724"
      },
      "source": [
        "# NTK-vector products\n",
        "k_2 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw6HL260K26E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84f71c5-a3ae-4379-e075-7e4e39c36a19"
      },
      "source": [
        "# Structured derivatives\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYG0fV9nOjnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aa345d1-738c-4a32-ddb7-18246b36d865"
      },
      "source": [
        "# Make sure kernels agree.\n",
        "print(\n",
        "    np.max(np.abs(k_1 - k_2)) / np.mean(np.abs(k_1)), \n",
        "    np.max(np.abs(k_1 - k_3)) / np.mean(np.abs(k_1)),\n",
        "    np.max(np.abs(k_2 - k_3)) / np.mean(np.abs(k_2))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0012127301 0.00071778375 0.0013034485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyF4M5_HK5Fk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19aa31ed-54e4-4934-b0ae-8ac9b5cc30dc"
      },
      "source": [
        "# Selects best method based on FLOPs at first call / compilation.\n",
        "# Takes about 3x more time to compile.\n",
        "# WARNING: due to an XLA issue, currently only works correctly on TPUs!\n",
        "# Wrong FLOPs for CPU/GPU of JITted functions.\n",
        "k_0 = ntk_fn_auto(x1, x2, params)\n",
        "print(k_0.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "impl=1, flops=6864798208.0\n",
            "impl=2, flops=7510242816.0\n",
            "impl=3, flops=6878602240.0\n",
            "(1, 1, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8g1IO71LLJlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eea4414b-951b-4a35-adde-81747e64d2da"
      },
      "source": [
        "%%timeit\n",
        "ntk_fn_jacobian_contraction(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 196 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEIPcXYRMys2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049d56fc-526d-42d5-e36d-07b082b37649"
      },
      "source": [
        "%%timeit\n",
        "# 3X faster!\n",
        "ntk_fn_ntvp(x1, x2, params).block_until_ready()  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 84.5 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVyUPA8xM1ot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bf6371b-ef69-4690-ddde-5339de233fc4"
      },
      "source": [
        "%%timeit\n",
        "# 4X faster!\n",
        "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 51 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o81r3UHJM34_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ba1519c-66f7-4ed3-a626-9fe535fccadc"
      },
      "source": [
        "%%timeit \n",
        "# On TPU should match the fastest method.\n",
        "# On GPU/CPU, currently is broken, and may not be the fastest.\n",
        "ntk_fn_auto(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 195 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dh_aFUZFXm_C"
      },
      "source": [
        "# $\\color{blue}O = 1000$ logits, batch size $\\color{red}N = 1$, full NTK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rs4KF07fjjv"
      },
      "source": [
        "Structured derivatives allows to compute full $1000\\times 1000$ ImageNet NTK. Other methods run out of memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4MpdSJ7hFsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd24edc-30d0-4d02-e8a8-f5115643a30b"
      },
      "source": [
        "O = 1000\n",
        "N = 1\n",
        "\n",
        "# Input images x\n",
        "input_shape = (224, 224, 3)\n",
        "k1, k2 = random.split(random.PRNGKey(1), 2)\n",
        "x1 = random.normal(k1, (N, *input_shape))\n",
        "x2 = random.normal(k2, (N, *input_shape))\n",
        "\n",
        "params, (ntk_fn_jacobian_contraction, ntk_fn_ntvp, ntk_fn_str_derivatives, ntk_fn_auto) = get_ntk_fns(O=O)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:absl:Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: \n",
            "INFO:absl:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBEtkA7d_2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a1783b3-d229-4a5b-e4a4-389290827a2e"
      },
      "source": [
        "# Structured derivatives - fits in memory!\n",
        "k_3 = ntk_fn_str_derivatives(x1, x2, params)\n",
        "print(k_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 1000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afniv9k2d_2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7909a103-18ec-44fc-bbb2-9b433751cdc4"
      },
      "source": [
        "%%timeit\n",
        "ntk_fn_str_derivatives(x1, x2, params).block_until_ready()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 343 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ou5a6y4zH5Q",
        "outputId": "ac0babcc-82d7-4713-97eb-fc5b538a733a"
      },
      "source": [
        "k_3 = ntk_fn_ntvp(x1, x2, params)\n",
        "print(k_3.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 1000, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSKnDNfhd_2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ba13b61e-c88e-4989-cbb2-3152496fcde1"
      },
      "source": [
        "%timeit\n",
        "k_3 = ntk_fn_ntvp(x1, x2, params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-64909048e3c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_ntvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 14184704680 bytes."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjXRalQfd_2G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "fd6b97a8-b334-4dc6-b1e0-2d5c9ece9acf"
      },
      "source": [
        "# Jacobian contraction - OOM!\n",
        "k_1 = ntk_fn_jacobian_contraction(x1, x2, params)\n",
        "print(k_1.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ae557f05f951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Jacobian contraction - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_jacobian_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         donated_invars=donated_invars, inline=inline)\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1617\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1618\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1609\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1610\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1620\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    624\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    959\u001b[0m           if x is not token and i in kept_var_idx))\n\u001b[0;32m--> 960\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnfilteredStackTrace\u001b[0m: RuntimeError: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 41414954560 bytes.\n\nThe stack trace below excludes JAX-internal frames.\nThe preceding is the original exception that occurred, unmodified.\n\n--------------------",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-ae557f05f951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Jacobian contraction - OOM!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mk_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mntk_fn_jacobian_contraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(compiled, avals, handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m    958\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m           if x is not token and i in kept_var_idx))\n\u001b[0;32m--> 960\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxla_call_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_partition_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 41414954560 bytes."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGknJIgjxT26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}